{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2965c631",
   "metadata": {},
   "source": [
    "# Data preparation for Spotify data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29181e19",
   "metadata": {},
   "source": [
    "Spotify is a digital music service that gives you access to millions of songs, and in 2021 has amassed 406 million active users, with 180 million premium subscribers.\n",
    "\n",
    "Many would probably be familiar with the [Spotify](https://spotifycharts.com/regional) and [Billboard](https://www.billboard.com/charts/) Charts. These lists are constantly evolving, and songs are added and taken off every day. \n",
    "\n",
    "[Spotify's API](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features) also provides features for every song, with their integration of the echonest API\n",
    "\n",
    "We want to find out if audio features can be used to predict a hit song, and if so, which models work best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93130b6f",
   "metadata": {},
   "source": [
    "### Libraries used in data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f75dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.chained_assignment = None # Pretty sure this will come back to stab me in the back\n",
    "\n",
    "githubrepo = 'https://raw.githubusercontent.com/joedav98/SC1015_SC18_SpotifyRepo/main/data/'\n",
    "# Data is uploaded to a github repo, in order to pull when we need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52116968",
   "metadata": {},
   "source": [
    "### Collection of functions for dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c92c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converttonumeric(final):\n",
    "    final.danceability = pd.to_numeric(final.danceability)\n",
    "    final.energy = pd.to_numeric(final.energy)\n",
    "    final.loudness = pd.to_numeric(final.loudness)\n",
    "    final.speechiness = pd.to_numeric(final.speechiness)\n",
    "    final.acousticness = pd.to_numeric(final.acousticness)\n",
    "    final.liveness = pd.to_numeric(final.liveness)\n",
    "    final.valence = pd.to_numeric(final.valence)\n",
    "    final.tempo = pd.to_numeric(final.tempo)\n",
    "    final.duration_ms = pd.to_numeric(final.duration_ms)\n",
    "    final.year = pd.to_numeric(final.year)\n",
    "# Function to convert all values to numeric\n",
    "\n",
    "def convertKeytoCat(df):\n",
    "    df['key'] = df['key'].replace({\n",
    "      0 : 'C', \n",
    "      1 : 'C#/Db', \n",
    "      2 : 'D', \n",
    "      3 : 'D#/Eb', \n",
    "      4 : 'E', \n",
    "      5 : 'F', \n",
    "      6 : 'F#/Gb', \n",
    "      7 : 'G', \n",
    "      8 : 'G#/Ab', \n",
    "      9 : 'A', \n",
    "      10 : 'A#/Bb', \n",
    "      11 : 'B'})\n",
    "# Convert key from numbers to letters\n",
    "  \n",
    "def convertKeytoNum(df):\n",
    "    drop20s['key'] = drop20s['key'].str[0].map({\n",
    "      'C' : 0, \n",
    "      'C#/Db' : 1, \n",
    "      'D' : 2, \n",
    "      'D#/Eb' : 3, \n",
    "      'E' : 4, \n",
    "      'F' : 5, \n",
    "      'F#/Gb' : 6, \n",
    "      'G' : 7, \n",
    "      'G#/Ab' : 8, \n",
    "      'A' : 9, \n",
    "      'A#/Bb' : 10, \n",
    "      'B' : 11})\n",
    "# Encode key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d327c3",
   "metadata": {},
   "source": [
    "## NonHit songs dataset\n",
    "\n",
    "Taken from https://www.kaggle.com/datasets/luckey01/test-data-set\n",
    "\n",
    "The original CSV files had to be split into separate files to upload to GitHub, so they are being recombined in the top of the code. Each decade had their own number of hit songs, thus an equal amount for each decade was sampled from the nonhits. Decade10 encountered some problems as there was a heavy skew towards the later years, thus they were manually sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5af2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonhit0 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_0.csv')\n",
    "nonhit1 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_1.csv')\n",
    "nonhit2 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_2.csv')\n",
    "nonhit3 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_3.csv')\n",
    "nonhit4 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_4.csv')\n",
    "nonhit5 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_5.csv')\n",
    "nonhit6 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_6.csv')\n",
    "\n",
    "\n",
    "nonhit1 = pd.DataFrame(data = nonhit1.values, columns = nonhit0.columns)\n",
    "nonhit2 = pd.DataFrame(data = nonhit2.values, columns = nonhit0.columns)\n",
    "nonhit3 = pd.DataFrame(data = nonhit3.values, columns = nonhit0.columns)\n",
    "nonhit4 = pd.DataFrame(data = nonhit4.values, columns = nonhit0.columns)\n",
    "nonhit5 = pd.DataFrame(data = nonhit5.values, columns = nonhit0.columns)\n",
    "nonhit6 = pd.DataFrame(data = nonhit6.values, columns = nonhit0.columns)\n",
    "\n",
    "\n",
    "nonhitmerge = pd.concat([nonhit0, nonhit1, nonhit2, nonhit3, nonhit4, nonhit5, nonhit6], ignore_index = True).sort_values(by = ['album_release_year'])\n",
    "\n",
    "nonhitpre = nonhitmerge.drop(labels = ['Unnamed: 0',\n",
    "                                        'spotify_id',\n",
    "                                        'album_release_date',\n",
    "                                        'album_release_month',\n",
    "                                        'analysis_url',\n",
    "                                        'mode',\n",
    "                                        'song_explicit',\n",
    "                                        'time_signature',\n",
    "                                        'total_available_markets',\n",
    "                                        'track_href',\n",
    "                                        'uri',\n",
    "                                        'instrumentalness'],\n",
    "                      axis = 1,\n",
    "                      inplace = False)\n",
    "\n",
    "nonhitpre.rename(columns = {'song_name':'track',\n",
    "                            'artist_name':'artist',\n",
    "                            'album_release_year':'year'},\n",
    "               inplace = True) # Renaming columns to merge with larger dataset\n",
    "\n",
    "nonhitprocess = nonhitpre[nonhitpre.song_popularity <= 50].dropna() # Using popularity feature to avoid hit songs\n",
    "nonhitprocess = nonhitprocess.drop(labels = ['song_popularity'], axis = 1, inplace = False)\n",
    "\n",
    "decade90nonhitpre = nonhitprocess[(nonhitprocess.year >= 1990) & (nonhitprocess.year <= 1999)].sort_values(by = ['year'])\n",
    "decade00nonhitpre = nonhitprocess[(nonhitprocess.year >= 2000) & (nonhitprocess.year <= 2009)].sort_values(by = ['year'])\n",
    "decade10nonhitpre1 = nonhitprocess[(nonhitprocess.year >= 2010) & (nonhitprocess.year <= 2018)].sort_values(by = ['year'])\n",
    "decade10nonhitpre2 = nonhitprocess[(nonhitprocess.year == 2019)].sort_values(by = ['year'])\n",
    "decade10nonhitpre3 = nonhitprocess[(nonhitprocess.year == 2020)].sort_values(by = ['year'])\n",
    "decade10nonhitpre4 = nonhitprocess[(nonhitprocess.year == 2021)].sort_values(by = ['year'])\n",
    "\n",
    "decade90nonhit = decade90nonhitpre.sample(n = 2700, random_state = 52)\n",
    "decade00nonhit = decade00nonhitpre.sample(n = 2830, random_state = 52)\n",
    "decade10nonhit1 = decade10nonhitpre1.sample(n = 2570, random_state = 52)\n",
    "decade10nonhit2 = decade10nonhitpre2.sample(n = 480, random_state = 52)\n",
    "decade10nonhit3 = decade10nonhitpre3.sample(n = 450, random_state = 52)\n",
    "decade10nonhit4 = decade10nonhitpre4.sample(n = 500, random_state = 52)\n",
    "\n",
    "decade10nonhit = pd.concat([decade10nonhit1, decade10nonhit2, decade10nonhit3, decade10nonhit4], join = 'inner')\n",
    "\n",
    "for nonhit in [decade90nonhit, decade00nonhit, decade10nonhit]:\n",
    "    nonhit['charted'] = False\n",
    "    nonhit['weeks-on-board'] = 0\n",
    "    converttonumeric(nonhit)\n",
    "    convertKeytoCat(nonhit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6411906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decade 90 NonHits: 2700\n",
      "Decade 00 NonHits: 2830\n",
      "Decade 10 NonHits: 4000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Decade 90 NonHits: {len(decade90nonhit.index)}\")\n",
    "print(f\"Decade 00 NonHits: {len(decade00nonhit.index)}\")\n",
    "print(f\"Decade 10 NonHits: {len(decade10nonhit.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e0b9c",
   "metadata": {},
   "source": [
    "## Hit songs from 2020 and 2021\n",
    "Taken from https://www.kaggle.com/datasets/sashankpillai/spotify-top-200-charts-20202021\n",
    "\n",
    "The original hit songs dataset that we acquired lacked data from 2020 to 2021, thus we had to find a separate dataset to fill in the gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492e6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data20s = pd.read_csv(githubrepo + 'dataset-of-20s.csv')\n",
    "data20s = data20s[data20s['Highest Charting Position'] <= 100] # Getting only top 100, instead of top 200\n",
    "drop20s = data20s.drop(labels = ['Index',\n",
    "                                 'Highest Charting Position',\n",
    "                                 'Week of Highest Charting',\n",
    "                                 'Streams',\n",
    "                                 'Artist Followers',\n",
    "                                 'Song ID',\n",
    "                                 'Genre',\n",
    "                                 'Popularity',\n",
    "                                 'Release Date'],\n",
    "                       axis = 1,\n",
    "                       inplace = False) # Dataset of hit songs from 2019 to 2021\n",
    "\n",
    "drop20s['Weeks Charted'] = drop20s['Weeks Charted'].str[:4] # Extracting year of charting from weeks charted\n",
    "\n",
    "drop20s.rename(columns = {'Number of Times Charted':'weeks-on-board',\n",
    "                          'Song Name':'track',\n",
    "                          'Artist':'artist',\n",
    "                          'Weeks Charted':'year',\n",
    "                          'Danceability':'danceability',\n",
    "                          'Energy':'energy',\n",
    "                          'Loudness':'loudness',\n",
    "                          'Speechiness':'speechiness',\n",
    "                          'Acousticness':'acousticness',\n",
    "                          'Liveness':'liveness',\n",
    "                          'Tempo':'tempo',\n",
    "                          'Duration (ms)':'duration_ms',\n",
    "                          'Valence':'valence',\n",
    "                          'Chord':'key'},\n",
    "               inplace = True) # Renaming columns to merge with larger dataset\n",
    "\n",
    "drop20s = drop20s.replace(r'^\\s*$', np.nan, regex=True)\n",
    "drop20s.dropna(subset=['danceability'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaa84b9",
   "metadata": {},
   "source": [
    "## Hit songs dataset\n",
    "Taken from \n",
    "\n",
    "https://www.kaggle.com/datasets/theoverman/the-spotify-hit-predictor-dataset\n",
    "\n",
    "https://www.kaggle.com/datasets/dhruvildave/spotify-charts\n",
    "\n",
    "First dataset was used to get the song features necessary for our analysis. Only data from 1990 to 2021 was extracted. The second dataset contained our billboard charts data, which included the number of weeks a song has been on the billboard charts. We used this to convert to a boolean feature that simply states whether or not a song is a hit.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a215cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data90s = pd.read_csv(githubrepo + 'dataset-of-90s.csv')\n",
    "data00s = pd.read_csv(githubrepo + 'dataset-of-00s.csv')\n",
    "data10s = pd.read_csv(githubrepo + 'dataset-of-10s.csv')\n",
    "charts = pd.read_csv(githubrepo + 'charts.csv').drop_duplicates(subset=['song', 'artist'], keep = 'first') \n",
    "# Dataset from Billboard, drop duplicates leaves only the latest occurence of a hit song\n",
    "\n",
    "datayears = [data90s, data00s, data10s] # Dataset of top tracks from 1960s to 2010s, with Echonest info\n",
    "reference = pd.concat(datayears, ignore_index = True).drop_duplicates(subset = ['track', 'artist'], keep = 'last') # Leaves only latest occurence of a hit song\n",
    "charts['date'] = charts['date'].str[:-6]\n",
    "\n",
    "dropref = reference.drop(labels = ['uri', \n",
    "                                   'mode',\n",
    "                                   'chorus_hit',\n",
    "                                   'sections',\n",
    "                                   'target',\n",
    "                                   'instrumentalness',\n",
    "                                   'time_signature'], \n",
    "                        axis = 1, \n",
    "                        inplace = False) # Dropping features that won't be helpful in analysis\n",
    "\n",
    "dropcharts = charts.drop(labels = ['rank', \n",
    "                                   'last-week',\n",
    "                                   'peak-rank'],\n",
    "                         axis = 1,\n",
    "                         inplace = False).reset_index(drop = True) # Dropping features that won't be helpful in analysis\n",
    "# Rank and peak rank can change in a single year, last week is redundant as we are using the year it charted\n",
    "\n",
    "mergedDF = pd.merge(dropref, dropcharts, left_on = ['track', 'artist'], right_on = ['song', 'artist']) # Merging Spotify data with Billboard data\n",
    "\n",
    "mergedDF = mergedDF.drop(labels = ['song'], axis = 1, inplace = False)\n",
    "mergedDF.rename(columns = {'date':'year'}, inplace = True)\n",
    "\n",
    "mergedDF.year = pd.to_numeric(mergedDF.year)\n",
    "\n",
    "decade90hit = mergedDF[(mergedDF.year >= 1990) & (mergedDF.year <= 1999)]\n",
    "decade00hit = mergedDF[(mergedDF.year >= 2000) & (mergedDF.year <= 2009)]\n",
    "decade10hit = mergedDF[(mergedDF.year >= 2010) & (mergedDF.year <= 2021)]\n",
    "\n",
    "decade10hit = pd.concat([decade10hit, drop20s], join = 'outer').drop_duplicates(subset = ['track', 'artist'], keep = 'last') # Joining the merged dataset with the dataset from 2019 to 2021, defaulting to merged dataset for clashes\n",
    "\n",
    "hits = [decade90hit, decade00hit, decade10hit]\n",
    "for hit in hits:\n",
    "    hit['charted'] = True\n",
    "    converttonumeric(hit)\n",
    "    convertKeytoCat(hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c284e7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decade 90 Hits: 2673\n",
      "Decade 00 Hits: 2831\n",
      "Decade 10 Hits: 4065\n"
     ]
    }
   ],
   "source": [
    "print(f\"Decade 90 Hits: {len(decade90hit.index)}\")\n",
    "print(f\"Decade 00 Hits: {len(decade00hit.index)}\")\n",
    "print(f\"Decade 10 Hits: {len(decade10hit.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7a39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade90 = pd.concat([decade90hit, decade90nonhit], join = 'inner').reset_index(drop = True)\n",
    "decade00 = pd.concat([decade00hit, decade00nonhit], join = 'inner').reset_index(drop = True)\n",
    "decade10 = pd.concat([decade10hit, decade10nonhit], join = 'inner').reset_index(drop = True)\n",
    "\n",
    "decadeHits = pd.concat([decade90hit,decade00hit,decade10hit], join = 'inner').reset_index(drop = True)\n",
    "decadeNonHits = pd.concat([decade90nonhit,decade00nonhit,decade10nonhit], join = 'inner').reset_index(drop = True)\n",
    "\n",
    "# Sorting by year then by weeks-on-board, resetting index as a final preparation of the dataset\n",
    "decade90 = decade90.sort_values(by = ['year', 'weeks-on-board']).reset_index(drop = True)\n",
    "decade00 = decade00.sort_values(by = ['year', 'weeks-on-board']).reset_index(drop = True)\n",
    "decade10 = decade10.sort_values(by = ['year', 'weeks-on-board']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fecd7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "prep = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "\n",
    "# Normalising values with MinMaxScaler()\n",
    "\n",
    "for decade in [decade90, decade00, decade10]:\n",
    "    decade[prep] = scaler.fit_transform(decade[prep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d172965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_names = ['track', \n",
    "                'artist', \n",
    "                'key', \n",
    "                'danceability', \n",
    "                'energy', \n",
    "                'loudness', \n",
    "                'speechiness', \n",
    "                'acousticness', \n",
    "                'liveness', \n",
    "                'valence', \n",
    "                'tempo', \n",
    "                'duration_ms', \n",
    "                'year', \n",
    "                'weeks-on-board', \n",
    "                'charted'] \n",
    "\n",
    "decade90 = decade90.reindex(columns = column_names)\n",
    "decade00 = decade00.reindex(columns = column_names)\n",
    "decade10 = decade10.reindex(columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e20ab",
   "metadata": {},
   "source": [
    "## Output main decades to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3bdbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade90nonhit.to_csv('output/eda/decade90nonhit.csv', index = False)\n",
    "decade00nonhit.to_csv('output/eda/decade00nonhit.csv', index = False)\n",
    "decade10nonhit.to_csv('output/eda/decade10nonhit.csv', index = False)\n",
    "\n",
    "decade90hit.to_csv('output/eda/decade90hit.csv', index = False)\n",
    "decade00hit.to_csv('output/eda/decade00hit.csv', index = False)\n",
    "decade10hit.to_csv('output/eda/decade10hit.csv', index = False)\n",
    "\n",
    "decade90.to_csv('output/decade90.csv', index = False)\n",
    "decade00.to_csv('output/decade00.csv', index = False)\n",
    "decade10.to_csv('output/decade10.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75c33c",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11413bdc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>key</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>year</th>\n",
       "      <th>weeks-on-board</th>\n",
       "      <th>charted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>If U Stay Ready</td>\n",
       "      <td>Suga Free</td>\n",
       "      <td>E</td>\n",
       "      <td>0.716037</td>\n",
       "      <td>0.687766</td>\n",
       "      <td>0.884529</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.038477</td>\n",
       "      <td>0.448589</td>\n",
       "      <td>0.448757</td>\n",
       "      <td>0.202938</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>Money Don't Matter 2 Night</td>\n",
       "      <td>Prince And The N.P.G.</td>\n",
       "      <td>C#/Db</td>\n",
       "      <td>0.841675</td>\n",
       "      <td>0.568677</td>\n",
       "      <td>0.786922</td>\n",
       "      <td>0.036137</td>\n",
       "      <td>0.029217</td>\n",
       "      <td>0.059619</td>\n",
       "      <td>0.708669</td>\n",
       "      <td>0.505929</td>\n",
       "      <td>0.202648</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>Ugly in the Morning</td>\n",
       "      <td>Faith No More</td>\n",
       "      <td>E</td>\n",
       "      <td>0.396323</td>\n",
       "      <td>0.977983</td>\n",
       "      <td>0.823127</td>\n",
       "      <td>0.077882</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.235471</td>\n",
       "      <td>0.323589</td>\n",
       "      <td>0.502235</td>\n",
       "      <td>0.130339</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>เมื่อรักฉันเกิด</td>\n",
       "      <td>Silly Fools</td>\n",
       "      <td>C#/Db</td>\n",
       "      <td>0.583248</td>\n",
       "      <td>0.714786</td>\n",
       "      <td>0.752122</td>\n",
       "      <td>0.043821</td>\n",
       "      <td>0.023695</td>\n",
       "      <td>0.158317</td>\n",
       "      <td>0.744960</td>\n",
       "      <td>0.422700</td>\n",
       "      <td>0.204099</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>I Got A Thang 4 Ya!</td>\n",
       "      <td>Lo-Key?</td>\n",
       "      <td>F#/Gb</td>\n",
       "      <td>0.772217</td>\n",
       "      <td>0.649737</td>\n",
       "      <td>0.836118</td>\n",
       "      <td>0.047456</td>\n",
       "      <td>0.308233</td>\n",
       "      <td>0.060721</td>\n",
       "      <td>0.794355</td>\n",
       "      <td>0.607662</td>\n",
       "      <td>0.241999</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           track                 artist    key  danceability  \\\n",
       "3861             If U Stay Ready              Suga Free      E      0.716037   \n",
       "1109  Money Don't Matter 2 Night  Prince And The N.P.G.  C#/Db      0.841675   \n",
       "2344         Ugly in the Morning          Faith No More      E      0.396323   \n",
       "4279             เมื่อรักฉันเกิด            Silly Fools  C#/Db      0.583248   \n",
       "1638         I Got A Thang 4 Ya!                Lo-Key?  F#/Gb      0.772217   \n",
       "\n",
       "        energy  loudness  speechiness  acousticness  liveness   valence  \\\n",
       "3861  0.687766  0.884529     0.219107      0.019478  0.038477  0.448589   \n",
       "1109  0.568677  0.786922     0.036137      0.029217  0.059619  0.708669   \n",
       "2344  0.977983  0.823127     0.077882      0.002098  0.235471  0.323589   \n",
       "4279  0.714786  0.752122     0.043821      0.023695  0.158317  0.744960   \n",
       "1638  0.649737  0.836118     0.047456      0.308233  0.060721  0.794355   \n",
       "\n",
       "         tempo  duration_ms    year  weeks-on-board  charted  \n",
       "3861  0.448757     0.202938  1997.0              13     True  \n",
       "1109  0.505929     0.202648  1992.0              13     True  \n",
       "2344  0.502235     0.130339  1995.0               0    False  \n",
       "4279  0.422700     0.204099  1998.0               0    False  \n",
       "1638  0.607662     0.241999  1993.0              20     True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train90, test90 = train_test_split(decade90, test_size = 0.2, random_state = 52)\n",
    "train00, test00 = train_test_split(decade00, test_size = 0.2, random_state = 52)\n",
    "train10, test10 = train_test_split(decade10, test_size = 0.2, random_state = 52)\n",
    "\n",
    "train90.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724cef6b",
   "metadata": {},
   "source": [
    "## Output Train and Test datasets to CSVs\n",
    "\n",
    "To be used with spotify_machine_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b6dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train90.to_csv('output/train/train90.csv', index = False)\n",
    "train00.to_csv('output/train/train00.csv', index = False)\n",
    "train10.to_csv('output/train/train10.csv', index = False)\n",
    "\n",
    "test90.to_csv('output/test/test90.csv', index = False)\n",
    "test00.to_csv('output/test/test00.csv', index = False)\n",
    "test10.to_csv('output/test/test10.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e859d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
